{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "96dOUkkjbR6O",
        "outputId": "8cf1f601-d410-4dbd-80a3-1404a94fcbfa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-52b93f31-8ad9-4fe7-9872-c4a18aa1f60e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-52b93f31-8ad9-4fe7-9872-c4a18aa1f60e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mnist_dataset.csv to mnist_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"mnist_dataset.csv\")"
      ],
      "metadata": {
        "id": "LE_B_QSYb1UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "T_CbAc7QcW-y",
        "outputId": "16baaefd-913d-4931-c77c-3893b72dff4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  \\\n",
              "0      5        0        0        0        0        0        0        0   \n",
              "1      0        0        0        0        0        0        0        0   \n",
              "2      4        0        0        0        0        0        0        0   \n",
              "3      1        0        0        0        0        0        0        0   \n",
              "4      9        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel_7  pixel_8  ...  pixel_774  pixel_775  pixel_776  pixel_777  \\\n",
              "0        0        0  ...          0          0          0          0   \n",
              "1        0        0  ...          0          0          0          0   \n",
              "2        0        0  ...          0          0          0          0   \n",
              "3        0        0  ...          0          0          0          0   \n",
              "4        0        0  ...          0          0          0          0   \n",
              "\n",
              "   pixel_778  pixel_779  pixel_780  pixel_781  pixel_782  pixel_783  \n",
              "0          0          0          0          0          0          0  \n",
              "1          0          0          0          0          0          0  \n",
              "2          0          0          0          0          0          0  \n",
              "3          0          0          0          0          0          0  \n",
              "4          0          0          0          0          0          0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25cb685f-242a-476d-99cc-1fd41eecf62c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel_0</th>\n",
              "      <th>pixel_1</th>\n",
              "      <th>pixel_2</th>\n",
              "      <th>pixel_3</th>\n",
              "      <th>pixel_4</th>\n",
              "      <th>pixel_5</th>\n",
              "      <th>pixel_6</th>\n",
              "      <th>pixel_7</th>\n",
              "      <th>pixel_8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel_774</th>\n",
              "      <th>pixel_775</th>\n",
              "      <th>pixel_776</th>\n",
              "      <th>pixel_777</th>\n",
              "      <th>pixel_778</th>\n",
              "      <th>pixel_779</th>\n",
              "      <th>pixel_780</th>\n",
              "      <th>pixel_781</th>\n",
              "      <th>pixel_782</th>\n",
              "      <th>pixel_783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25cb685f-242a-476d-99cc-1fd41eecf62c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25cb685f-242a-476d-99cc-1fd41eecf62c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25cb685f-242a-476d-99cc-1fd41eecf62c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a6d9cee0-4879-4468-9e34-969c7301ab05\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6d9cee0-4879-4468-9e34-969c7301ab05')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a6d9cee0-4879-4468-9e34-969c7301ab05 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(z):\n",
        "    \"\"\"\n",
        "    Compute the softmax probabilities for a given input matrix.\n",
        "\n",
        "    Parameters:\n",
        "    z (numpy.ndarray): Logits (raw scores) of shape (m, n), where\n",
        "        - m is the number of samples.\n",
        "        - n is the number of classes.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Softmax probability matrix of shape (m, n), where\n",
        "        each row sums to 1 and represents the probability\n",
        "        distribution over classes.\n",
        "\n",
        "    Notes:\n",
        "    - The input to softmax is typically computed as: z = XW + b.\n",
        "    - Uses numerical stabilization by subtracting the max value per row.\n",
        "    \"\"\"\n",
        "    z = z - np.max(z, axis=1, keepdims=True)  # Prevents large values\n",
        "    exp_z = np.exp(z)  # Apply exponent\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)  # Normalize"
      ],
      "metadata": {
        "id": "a7bC0ychcYgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This test case checks that each row in the resulting softmax probabilities sums to 1, which is the\n",
        "\n",
        "# Example test case\n",
        "\n",
        "\n",
        "\n",
        "z_test = np.array([[2.0, 1.0, 0.1], [1.0, 1.0, 1.0]])\n",
        "softmax_output = softmax(z_test)\n",
        "# Verify if the sum of probabilities for each row is 1 using assert\n",
        "row_sums = np.sum(softmax_output, axis=1)\n",
        "# Assert that the sum of each row is 1\n",
        "assert np.allclose(row_sums, 1), f\"Test failed: Row sums are {row_sums}\"\n",
        "print(\"Softmax function passed the test case!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XW6_GS5cl2n",
        "outputId": "93067f3b-9044-4d90-b714-fbeede61a710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax function passed the test case!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_softmax(X, W, b):\n",
        "    \"\"\"\n",
        "    Predict class labels using a trained softmax model.\n",
        "\n",
        "    Steps:\n",
        "    1. Compute raw scores (logits) using the formula: z = XW + b.\n",
        "    2. Apply softmax to turn raw scores into probabilities.\n",
        "    3. Pick the class with the highest probability for each sample.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix (n, d), where:\n",
        "        - n = number of samples (rows)\n",
        "        - d = number of features (columns)\n",
        "    W (numpy.ndarray): Weight matrix (d, c), where:\n",
        "        - c = number of classes\n",
        "    b (numpy.ndarray): Bias vector (c,).\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Predicted class labels (n,), each value is a class index.\n",
        "    \"\"\"\n",
        "\n",
        "    z = np.dot(X, W) + b\n",
        "\n",
        "\n",
        "    z = z - np.max(z, axis=1, keepdims=True)\n",
        "    exp_z = np.exp(z)\n",
        "    softmax_probs = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "    predicted_classes = np.argmax(softmax_probs, axis=1)\n",
        "\n",
        "    return predicted_classes"
      ],
      "metadata": {
        "id": "bZbsF671dXUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The test function ensures that the predicted class labels have the same number of elements as the\n",
        "\n",
        "# Define test case\n",
        "X_test = np.array([[0.2, 0.8], [0.5, 0.5], [0.9, 0.1]]) # Feature matrix (3 samples, 2 features)\n",
        "W_test = np.array([[0.4, 0.2, 0.1], [0.3, 0.7, 0.5]]) # Weights (2 features, 3 classes)\n",
        "b_test = np.array([0.1, 0.2, 0.3]) # Bias (3 classes)\n",
        "# Expected Output:\n",
        "# The function should return an array with class labels (0, 1, or 2)\n",
        "y_pred_test = predict_softmax(X_test, W_test, b_test)\n",
        "# Validate output shape\n",
        "assert y_pred_test.shape == (3,), f\"Test failed: Expected shape (3,), got {y_pred_test.shape}\"\n",
        "# Print the predicted labels\n",
        "print(\"Predicted class labels:\", y_pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U9hwFsWdmKR",
        "outputId": "90f65cb7-aef1-4841-fccd-737da658d36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class labels: [1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_softmax(y_pred,y):\n",
        " \"\"\"\n",
        " Computethecross-entropylossforasinglesample.\n",
        " Parameters:\n",
        " y_pred(numpy.ndarray):Predictedprobabilitiesofshape(c,)forasinglesample,\n",
        " wherecisthenumberofclasses.\n",
        " y (numpy.ndarray):Truelabels(one-hotencoded)ofshape(c,),wherecisthenumber ofclasses.\n",
        " Returns:\n",
        " float:Cross-entropylossforthegivensample.\n",
        " \"\"\"\n",
        " loss = np.sum(y* np.log(y_pred))\n",
        " return loss"
      ],
      "metadata": {
        "id": "acDJiyYfe7fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Softmax function to convert logits to probabilities\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # Stabilize exponentiation\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "# Cross-entropy loss function\n",
        "def loss_softmax(y_pred, y_true):\n",
        "    # Compute the softmax probabilities for the predicted values\n",
        "    y_pred_softmax = softmax(y_pred)\n",
        "\n",
        "    # Calculate cross-entropy loss (negative log likelihood)\n",
        "    # Clip the predicted probabilities to avoid log(0)\n",
        "    epsilon = 1e-15\n",
        "    y_pred_softmax = np.clip(y_pred_softmax, epsilon, 1. - epsilon)\n",
        "\n",
        "    # Cross-entropy loss formula\n",
        "    loss = -np.sum(y_true * np.log(y_pred_softmax)) / y_true.shape[0]\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Define correct predictions (low loss scenario)\n",
        "y_true_correct = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])  # True one-hot labels\n",
        "y_pred_correct = np.array([[0.9, 0.05, 0.05],\n",
        "                           [0.1, 0.85, 0.05],\n",
        "                           [0.05, 0.1, 0.85]])  # High confidence in the correct class\n",
        "\n",
        "# Define incorrect predictions (high loss scenario)\n",
        "y_pred_incorrect = np.array([[0.05, 0.05, 0.9],  # Highly confident in the wrong class\n",
        "                             [0.1, 0.05, 0.85],\n",
        "                             [0.85, 0.1, 0.05]])\n",
        "\n",
        "# Compute loss for both cases\n",
        "loss_correct = loss_softmax(y_pred_correct, y_true_correct)\n",
        "loss_incorrect = loss_softmax(y_pred_incorrect, y_true_correct)\n",
        "\n",
        "# Validate that incorrect predictions lead to a higher loss\n",
        "assert loss_correct < loss_incorrect, f\"Test failed: Expected loss_correct < loss_incorrect, but got {loss_correct:.4f} >= {loss_incorrect:.4f}\"\n",
        "\n",
        "# Print results\n",
        "print(f\"Cross-Entropy Loss (Correct Predictions): {loss_correct:.4f}\")\n",
        "print(f\"Cross-Entropy Loss (Incorrect Predictions): {loss_incorrect:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26HUAv_Lfitq",
        "outputId": "205f7799-c400-41dc-efc1-124b88c7fa90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Entropy Loss (Correct Predictions): 0.6414\n",
            "Cross-Entropy Loss (Incorrect Predictions): 1.4581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_softmax(X, y, W, b):\n",
        "    \"\"\"\n",
        "    Compute the average softmax regression cost (cross-entropy loss) over all samples.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d).\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    float: Average softmax cost (cross-entropy loss) over all samples.\n",
        "    \"\"\"\n",
        "    # Compute logits (raw scores)\n",
        "    logits = np.dot(X, W) + b\n",
        "\n",
        "    # Use previously defined softmax function\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    # Compute loss using vectorized approach\n",
        "    total_loss = -np.sum(y * np.log(probs + 1e-9))  # Adding small value for numerical stability\n",
        "\n",
        "    return total_loss / X.shape[0]  # Average loss over all sample"
      ],
      "metadata": {
        "id": "sSAsrvTvkZri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_softmax(X, y, W, b):\n",
        "    \"\"\"\n",
        "    Compute the average softmax regression cost (cross-entropy loss) over all samples.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d).\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    float: Average softmax cost (cross-entropy loss) over all samples.\n",
        "    \"\"\"\n",
        "    # Compute logits (raw scores)\n",
        "    logits = np.dot(X, W) + b\n",
        "\n",
        "    # Use previously defined softmax function\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    # Compute loss using vectorized approach\n",
        "    total_loss = -np.sum(y * np.log(probs + 1e-9))  # Adding small value for numerical stability\n",
        "\n",
        "    return total_loss / X.shape[0]  # Average loss over all samples\n",
        "# The test case assures that the cost for the incorrect prediction should be higher than for the\n",
        "\n",
        "import numpy as np\n",
        "# Example 1: Correct Prediction (Closer predictions)\n",
        "X_correct = np.array([[1.0, 0.0], [0.0, 1.0]]) # Feature matrix for correct predictions\n",
        "y_correct = np.array([[1, 0], [0, 1]]) # True labels (one-hot encoded, matching predictions)\n",
        "W_correct = np.array([[5.0, -2.0], [-3.0, 5.0]]) # Weights for correct prediction\n",
        "b_correct = np.array([0.1, 0.1]) # Bias for correct prediction\n",
        "# Example 2: Incorrect Prediction (Far off predictions)\n",
        "X_incorrect = np.array([[0.1, 0.9], [0.8, 0.2]]) # Feature matrix for incorrect predictions\n",
        "y_incorrect = np.array([[1, 0], [0, 1]]) # True labels (one-hot encoded, incorrect predictions)\n",
        "W_incorrect = np.array([[0.1, 2.0], [1.5, 0.3]]) # Weights for incorrect prediction\n",
        "b_incorrect = np.array([0.5, 0.6]) # Bias for incorrect prediction\n",
        "# Compute cost for correct predictions\n",
        "cost_correct = cost_softmax(X_correct, y_correct, W_correct, b_correct)\n",
        "# Compute cost for incorrect predictions\n",
        "cost_incorrect = cost_softmax(X_incorrect, y_incorrect, W_incorrect, b_incorrect)\n",
        "# Check if the cost for incorrect predictions is greater than for correct predictions\n",
        "assert cost_incorrect > cost_correct, f\"Test failed: Incorrect cost {cost_incorrect} is not greater than correct cost {cost_correct}\"\n",
        "# Print the costs for verification\n",
        "print(\"Cost for correct prediction:\", cost_correct)\n",
        "print(\"Cost for incorrect prediction:\", cost_incorrect)\n",
        "print(\"Test passed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgZlOBc7lCEn",
        "outputId": "a4c8c096-f46b-4764-a6c7-f2820cbe9904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost for correct prediction: 0.0006234354127112888\n",
            "Cost for incorrect prediction: 0.2993086122417495\n",
            "Test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_softmax(X, y, W, b):\n",
        "    \"\"\"\n",
        "    Compute the gradients of the cost function with respect to weights and biases.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d).\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    tuple: Gradients with respect to weights (d, c) and biases (c,).\n",
        "    \"\"\"\n",
        "    # Compute logits and apply softmax\n",
        "    logits = np.dot(X, W) + b\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    # Compute gradients\n",
        "    grad_W = np.dot(X.T, (probs - y)) / X.shape[0]\n",
        "    grad_b = np.sum(probs - y, axis=0) / X.shape[0]\n",
        "\n",
        "    return grad_W, grad_b"
      ],
      "metadata": {
        "id": "mOHeWIwzng4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Define a simple feature matrix and true labels\n",
        "X_test = np.array([[0.2, 0.8], [0.5, 0.5], [0.9, 0.1]]) # Feature matrix (3 samples, 2 features)\n",
        "y_test = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]) # True labels (one-hot encoded, 3 classes)\n",
        "# Define weight matrix and bias vector\n",
        "W_test = np.array([[0.4, 0.2, 0.1], [0.3, 0.7, 0.5]]) # Weights (2 features, 3 classes)\n",
        "b_test = np.array([0.1, 0.2, 0.3]) # Bias (3 classes)\n",
        "# Compute the gradients using the function\n",
        "grad_W, grad_b = compute_gradient_softmax(X_test, y_test, W_test, b_test)\n",
        "# Manually compute the predicted probabilities (using softmax function)\n",
        "z_test = np.dot(X_test, W_test) + b_test\n",
        "y_pred_test = softmax(z_test)\n",
        "# Compute the manually computed gradients\n",
        "grad_W_manual = np.dot(X_test.T, (y_pred_test - y_test)) / X_test.shape[0]\n",
        "grad_b_manual = np.sum(y_pred_test - y_test, axis=0) / X_test.shape[0]\n",
        "# Assert that the gradients computed by the function match the manually computed gradients\n",
        "assert np.allclose(grad_W, grad_W_manual), f\"Test failed: Gradients w.r.t. W are not equal.\\\n",
        "nExpected: {grad_W_manual}\\nGot: {grad_W}\"\n",
        "assert np.allclose(grad_b, grad_b_manual), f\"Test failed: Gradients w.r.t. b are not equal.\\\n",
        "nExpected: {grad_b_manual}\\nGot: {grad_b}\"\n",
        "# Print the gradients for verification\n",
        "print(\"Gradient w.r.t. W:\", grad_W)\n",
        "print(\"Gradient w.r.t. b:\", grad_b)\n",
        "print(\"Test passed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U3cbrGensCS",
        "outputId": "9e288dc8-104e-44fd-ddd3-b221c668ea39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient w.r.t. W: [[ 0.1031051   0.01805685 -0.12116196]\n",
            " [-0.13600547  0.00679023  0.12921524]]\n",
            "Gradient w.r.t. b: [-0.03290036  0.02484708  0.00805328]\n",
            "Test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_softmax(X, y, W, b, alpha, n_iter, show_cost=False):\n",
        "    \"\"\"\n",
        "    Perform gradient descent to optimize weights and biases.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d).\n",
        "    y (numpy.ndarray): One-hot encoded labels of shape (n, c).\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "    alpha (float): Learning rate.\n",
        "    n_iter (int): Number of iterations.\n",
        "    show_cost (bool): Whether to display the cost at intervals.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Optimized weights, biases, and cost history.\n",
        "    \"\"\"\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        grad_W, grad_b, cost = compute_gradient_softmax(X, y, W, b)\n",
        "\n",
        "        W -= alpha * grad_W\n",
        "        b -= alpha * grad_b\n",
        "\n",
        "        cost_history.append(cost)\n",
        "\n",
        "        if show_cost and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: Cost = {cost:.4f}\")\n",
        "\n",
        "    return W, b, cost_history"
      ],
      "metadata": {
        "id": "D4-_xHSxns80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_prepare_mnist(csv_file, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Reads the MNIST CSV file, splits data into train/test sets, and plots one image per class.\n",
        "\n",
        "    Arguments:\n",
        "    csv_file (str) : Path to the CSV file containing MNIST data.\n",
        "    test_size (float) : Proportion of the data to use as the test set (default: 0.2).\n",
        "    random_state (int) : Random seed for reproducibility (default: 42).\n",
        "\n",
        "    Returns:\n",
        "    X_train, X_test, y_train, y_test : Split dataset.\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    # df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Separate labels and features\n",
        "    y = df.iloc[:, 0].values  # First column is the label\n",
        "    X = df.iloc[:, 1:].values  # Remaining columns are pixel values\n",
        "\n",
        "    # Normalize pixel values (optional but recommended)\n",
        "    X = X / 255.0  # Scale values between 0 and 1\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Plot one sample image per class\n",
        "    plot_sample_images(X_train, y_train)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def plot_sample_images(X, y):\n",
        "    \"\"\"\n",
        "    Plots one sample image for each digit class (0-9).\n",
        "\n",
        "    Arguments:\n",
        "    X (np.ndarray): Feature matrix containing pixel values.\n",
        "    y (np.ndarray): Labels corresponding to images.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    unique_classes = np.unique(y)  # Get unique class labels\n",
        "\n",
        "    for i, digit in enumerate(unique_classes):\n",
        "        index = np.where(y == digit)[0][0]  # Find first occurrence of the class\n",
        "        image = X[index].reshape(28, 28)  # Reshape 1D array to 28x28\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(image, cmap='gray')  # Corrected quotation marks\n",
        "        plt.title(f\"Digit: {digit}\")\n",
        "        plt.axis('off')  # Corrected quotation marks\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()  # Ensure this is called to render the plot\n",
        "\n",
        "# Load and prepare dataset\n",
        "X_train, X_test, y_train, y_test = load_and_prepare_mnist('mnist_dataset.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "eLpssADVpIKn",
        "outputId": "61990150-fddc-4867-d427-2e924726df82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert that X and y have matching lengths\n",
        "assert len(X_train) == len(y_train), f\"Error: X and y have different lengths! X={len(X_train)}, y={len(y_train)}\"\n",
        "print(\"Move forward: Dimension of Feture Matrix X and label vector y matched.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si8QpXWzqMvH",
        "outputId": "98f92ea8-032c-4ad4-a887-f39763409aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Move forward: Dimension of Feture Matrix X and label vector y matched.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_classification(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluate classification performance using confusion matrix, precision, recall, and F1-score.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (numpy.ndarray): True labels\n",
        "    y_pred (numpy.ndarray): Predicted labels\n",
        "\n",
        "    Returns:\n",
        "    tuple: Confusion matrix, precision, recall, F1 score\n",
        "    \"\"\"\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Compute precision, recall, and F1-score\n",
        "    precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    return cm, precision, recall, f1"
      ],
      "metadata": {
        "id": "1C9AIxoyqQ9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}